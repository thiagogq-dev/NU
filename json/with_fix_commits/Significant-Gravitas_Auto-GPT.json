[
    {
        "repo_name": "Significant-Gravitas/Auto-GPT",
        "CVE_ID": "CVE-2023-37273",
        "Problem_Type": "CWE-94",
        "Description": "Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. Running Auto-GPT version prior to 0.4.3 by cloning the git repo and executing `docker compose run auto-gpt` in the repo root uses a different docker-compose.yml file from the one suggested in the official docker set up instructions. The docker-compose.yml file located in the repo root mounts itself into the docker container without write protection. This means that if malicious custom python code is executed via the `execute_python_file` and `execute_python_code` commands, it can overwrite the docker-compose.yml file and abuse it to gain control of the host system the next time Auto-GPT is started. The issue has been patched in version 0.4.3.",
        "URL": "https://github.com/Significant-Gravitas/Auto-GPT/pull/4761",
        "Commit SHA": "321edc5e3db0e801430d51aacfa0c343883ee52d",
        "Tag": "['Patch', 'Third Party Advisory']"
    },
    {
        "repo_name": "Significant-Gravitas/Auto-GPT",
        "CVE_ID": "CVE-2023-37274",
        "Problem_Type": "CWE-94",
        "Description": "Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. When Auto-GPT is executed directly on the host system via the provided run.sh or run.bat files, custom Python code execution is sandboxed using a temporary dedicated docker container which should not have access to any files outside of the Auto-GPT workspace directory.\nBefore v0.4.3, the `execute_python_code` command (introduced in v0.4.1) does not sanitize the `basename` arg before writing LLM-supplied code to a file with an LLM-supplied name. This allows for a path traversal attack that can overwrite any .py file outside the workspace directory by specifying a `basename` such as `../../../main.py`. This can further be abused to achieve arbitrary code execution on the host running Auto-GPT by e.g. overwriting autogpt/main.py which will be executed outside of the docker environment meant to sandbox custom python code execution the next time Auto-GPT is started. The issue has been patched in version 0.4.3. As a workaround, the risk introduced by this vulnerability can be remediated by running Auto-GPT in a virtual machine, or another environment in which damage to files or corruption of the program is not a critical problem.",
        "URL": "https://github.com/Significant-Gravitas/Auto-GPT/pull/4756",
        "Commit SHA": "32038c9f5b415c4781ae78b8821149305c46013a",
        "Tag": "['Patch', 'Third Party Advisory']"
    },
    {
        "repo_name": "Significant-Gravitas/Auto-GPT",
        "CVE_ID": "CVE-2023-37275",
        "Problem_Type": "CWE-117",
        "Description": "Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. The Auto-GPT command line UI makes heavy use of color-coded print statements to signify different types of system messages to the user, including messages that are crucial for the user to review and control which commands should be executed. Before v0.4.3, it was possible for a malicious external resource (such as a website browsed by Auto-GPT) to cause misleading messages to be printed to the console by getting the LLM to regurgitate JSON encoded ANSI escape sequences (`\\u001b[`). These escape sequences were JSON decoded and printed to the console as part of the model's \"thinking process\". The issue has been patched in release version 0.4.3.\n",
        "URL": "https://github.com/Significant-Gravitas/Auto-GPT/pull/4810",
        "Commit SHA": "bafcdcea7c89ffa1cdac037673b9110a6313e086",
        "Tag": "['Patch', 'Third Party Advisory']"
    }
]